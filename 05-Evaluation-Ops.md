# 05. 評測與工程 (Evaluation & Ops)

RAG 系統上線前，必須經過嚴謹的自動化評測。同時，為了追求極致效果，微調 (Fine-tuning) 也是常見的工程手段。

## 1. RAGAS 評測框架

RAGAS (Retrieval Augmented Generation Assessment) 是一個主流的開源評測框架，它不需要人工標註的「標準答案」，而是利用 LLM 作為裁判 (LLM-as-a-Judge) 來進行評分。

### 1.1 核心指標 (The RAG Triad)

1.  **Context Precision (上下文精準度)**:
    *   **定義**: 檢索回來的 Top-K 文檔中，真正包含答案的文檔排在多前面？
    *   **目標**: 確保有用資訊的信噪比高，且排序靠前。

2.  **Faithfulness (忠實度)**:
    *   **定義**: 生成的答案是否**完全基於**檢索到的上下文？
    *   **檢測幻覺**: 如果答案裡出現了上下文中沒有的資訊，Faithfulness 分數就會低。

3.  **Answer Relevance (答案相關性)**:
    *   **定義**: 生成的答案是否真正回答了用戶的問題？
    *   **目標**: 避免答非所問。

### 1.2 計算方式
RAGAS 通常會使用 GPT-4 作為裁判。
*   輸入: (Question, Context, Answer)
*   Prompt: "請檢查 Answer 中的每一句話是否都能在 Context 中找到依據。計算支持語句的比例。"

---

## 2. 幻覺 (Hallucination)

### 2.1 檢測方法
除了使用 RAGAS 的 Faithfulness 指標，還可以在工程上加入：
*   **引用檢查 (Citation Check)**: 強制模型在生成時輸出 `[Doc ID]`。後處理腳本檢查該 ID 對應的文檔是否真的包含該語句的關鍵詞。
*   **一致性檢查 (Self-Consistency)**: 讓 LLM 生成三次答案，比較這三次答案的邏輯是否一致。如果不一致，說明模型在瞎編。

### 2.2 緩解策略
*   **CoT (Chain of Thought)**: 在 Prompt 中加入 "Let's think step by step" 或要求 "先引用原文，再進行總結"。
*   **System Prompt 約束**: 強調 "如果你不知道，請直接回答不知道，不要編造"。
*   **降低 Temperature**: 將生成溫度設為 0，減少隨機性。

---

## 3. 模型微調 (Fine-tuning)

當通用的 LLM (如 GPT-4, Llama-3) 在特定領域（如醫療、法律）表現不佳時，我們可以考慮微調。

### 3.1 什麼是 LoRA (Low-Rank Adaptation)?
全參數微調 (Full Fine-tuning) 需要更新模型的所有參數，成本極高且容易發生「災難性遺忘」。
**LoRA** 是一種 PEFT (Parameter-Efficient Fine-Tuning) 技術。
*   **原理**: 凍結預訓練模型的主參數，只在每一層旁路插入兩個低秩矩陣 (A 和 B)。訓練時只更新這兩個小矩陣。
*   **優勢**: 顯存佔用極低（可以在單張消費級顯卡上微調大模型），訓練速度快。

### 3.2 RAG vs SFT (Supervised Fine-Tuning)
這是一個經典的選擇題：**該用 RAG 還是該微調？**

| 特性 | RAG (檢索增強) | SFT (監督微調) |
| :--- | :--- | :--- |
| **知識來源** | 外部資料庫 (動態) | 模型權重 (靜態) |
| **更新頻率** | 即時 | 需要重新訓練 |
| **消除幻覺** | 效果好 (有據可查) | 較難 (依賴記憶) |
| **特定格式/語氣** | 較弱 (依賴 Prompt) | **強項** (能學會特定文風) |
| **成本** | 檢索成本 + Token 費 | 訓練成本 + 部署成本 |

### 3.3 最佳實踐：RAG + SFT
兩者不是互斥的，而是互補的。
*   用 **SFT** 讓模型學會「如何使用工具」、「如何遵循特定指令格式」或「學習領域術語」。
*   用 **RAG** 提供最新的「事實數據」。
*   **例子**: 訓練一個醫療助手，用 SFT 讓它學會像醫生一樣說話（語氣、術語），用 RAG 讓它查詢最新的藥品說明書（事實）。
